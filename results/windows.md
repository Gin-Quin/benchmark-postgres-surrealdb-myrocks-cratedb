# Postgres

bun run .\tests\postgres.ts          
============================================================
ğŸ§ª PostgreSQL Performance Benchmark
============================================================

ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: {
  rss: 321,
  heapUsed: 16,
  heapTotal: 17,
  external: 6,
}

--- EMPTY DB BENCHMARK ---
[122.97ms] Insert 2048 authors
[68.90ms] Pick authors
[6.14ms] Select benchmark authors
[2.75ms] Complex analytical query
[4.30ms] Aggregation query
Memory usage - Before: 321MB, After: 353MB, Diff: 32MB

ğŸ“¦ PHASE 2: Loading bulk data...
Adding 1â€¯000â€¯000 records...
Inserting 1â€¯000â€¯000 records in 100 batches of 10â€¯000...
  Completed 100â€¯000 / 1â€¯000â€¯000 records
  Completed 200â€¯000 / 1â€¯000â€¯000 records
  Completed 300â€¯000 / 1â€¯000â€¯000 records
  Completed 400â€¯000 / 1â€¯000â€¯000 records
  Completed 500â€¯000 / 1â€¯000â€¯000 records
  Completed 600â€¯000 / 1â€¯000â€¯000 records
  Completed 700â€¯000 / 1â€¯000â€¯000 records
  Completed 800â€¯000 / 1â€¯000â€¯000 records
  Completed 900â€¯000 / 1â€¯000â€¯000 records
  Completed 1â€¯000â€¯000 / 1â€¯000â€¯000 records
âœ… Bulk insert completed successfully
[13.63s] Bulk data insert
Database now contains 1â€¯002â€¯048 total records
Memory after bulk insert: {
  rss: 440,
  heapUsed: 39,
  heapTotal: 38,
  external: 24,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[42.58ms] Insert 2048 authors
[37.49ms] Pick authors
[56.73ms] Select benchmark authors
[341.91ms] Complex analytical query
[1362.76ms] Aggregation query
Memory usage - Before: 440MB, After: 441MB, Diff: 1MB

ğŸ Benchmark complete!


# Timescale

bun run .\tests\postgres_timescale.ts
ğŸ”§ Initializing PostgreSQL with TimescaleDB extension...
âœ… TimescaleDB extension loaded
ğŸ•°ï¸ Converting AUTHORS table to hypertable...
ğŸ“Š Creating continuous aggregates...
âš™ï¸ Adding continuous aggregate refresh policies...
âœ… TimescaleDB continuous aggregates created successfully
============================================================
ğŸ§ª PostgreSQL TimescaleDB Performance Benchmark
============================================================

ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: {
  rss: 309,
  heapUsed: 16,
  heapTotal: 18,
  external: 6,
}

--- EMPTY DB BENCHMARK ---
[119.92ms] Insert 2048 authors
[86.48ms] Pick authors
[9.52ms] Select benchmark authors
[4.35ms] Complex analytical query (TimescaleDB)
[5.12ms] Complex analytical query (Standard)
[3.49ms] Aggregation query (TimescaleDB)
[4.79ms] Aggregation query (Standard)
[3.20ms] Hourly statistics query
[2.87ms] Real-time stats query
Memory usage - Before: 309MB, After: 343MB, Diff: 34MB

ğŸ“¦ PHASE 2: Loading bulk data...
Adding 1â€¯000â€¯000 records...
Inserting 1â€¯000â€¯000 records in 100 batches of 10â€¯000...
  Completed 100â€¯000 / 1â€¯000â€¯000 records
  Completed 200â€¯000 / 1â€¯000â€¯000 records
  Completed 300â€¯000 / 1â€¯000â€¯000 records
  Completed 400â€¯000 / 1â€¯000â€¯000 records
  Completed 500â€¯000 / 1â€¯000â€¯000 records
  Completed 600â€¯000 / 1â€¯000â€¯000 records
  Completed 700â€¯000 / 1â€¯000â€¯000 records
  Completed 800â€¯000 / 1â€¯000â€¯000 records
  Completed 900â€¯000 / 1â€¯000â€¯000 records
  Completed 1â€¯000â€¯000 / 1â€¯000â€¯000 records
âœ… Bulk insert completed successfully
ğŸ“Š Continuous aggregates will be updated automatically
[123.90s] Bulk data insert
Database now contains 1â€¯002â€¯048 total records
Memory after bulk insert: {
  rss: 406,
  heapUsed: 21,
  heapTotal: 25,
  external: 7,
}

â³ Waiting for continuous aggregates to refresh...
ğŸ”„ Manually refreshing continuous aggregates...
âœ… Continuous aggregates refreshed

ğŸ“Š PHASE 3: Benchmark with populated database

ğŸ”„ Manually refreshing continuous aggregates...
âœ… Continuous aggregates refreshed

ğŸ”„ Manually refreshing continuous aggregates...
âœ… Continuous aggregates refreshed
ğŸ”„ Manually refreshing continuous aggregates...
ğŸ”„ Manually refreshing continuous aggregates...
ğŸ”„ Manually refreshing continuous aggregates...
âœ… Continuous aggregates refreshed

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[96.69ms] Insert 2048 authors
[17.91s] Pick authors
[800.08ms] Select benchmark authors
--- POPULATED DB BENCHMARK ---
[96.69ms] Insert 2048 authors
[17.91s] Pick authors
[800.08ms] Select benchmark authors
[32.10ms] Complex analytical query (TimescaleDB)
[551.41ms] Complex analytical query (Standard)
[6.57ms] Aggregation query (TimescaleDB)
[32.10ms] Complex analytical query (TimescaleDB)
[551.41ms] Complex analytical query (Standard)
[6.57ms] Aggregation query (TimescaleDB)
[1207.82ms] Aggregation query (Standard)
[5.98ms] Hourly statistics query
[4.33ms] Real-time stats query
Memory usage - Before: 406MB, After: 409MB, Diff: 3MB
[1207.82ms] Aggregation query (Standard)
[5.98ms] Hourly statistics query
[4.33ms] Real-time stats query
Memory usage - Before: 406MB, After: 409MB, Diff: 3MB

ğŸ Benchmark complete!


# SurrealDB

bun run .\tests\surreal.ts
============================================================
ğŸ§ª SurrealDB Performance Benchmark
============================================================

ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: {
  rss: 293,
ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: {
  rss: 293,
  heapUsed: 14,
  heapTotal: 16,
  external: 5,
}

--- EMPTY DB BENCHMARK ---
[62.22ms] Insert 2048 authors
[189.01ms] Pick authors
  heapUsed: 14,
  heapTotal: 16,
  external: 5,
}

--- EMPTY DB BENCHMARK ---
[62.22ms] Insert 2048 authors
[189.01ms] Pick authors
[320.61ms] Select benchmark authors
[10.53ms] Complex analytical query
[10.94ms] Aggregation query
Memory usage - Before: 293MB, After: 308MB, Diff: 15MB

ğŸ“¦ PHASE 2: Loading bulk data...
Adding 1â€¯000â€¯000 records...
Inserting 1â€¯000â€¯000 records in 100 batches of 10â€¯000...
[320.61ms] Select benchmark authors
[10.53ms] Complex analytical query
[10.94ms] Aggregation query
Memory usage - Before: 293MB, After: 308MB, Diff: 15MB

ğŸ“¦ PHASE 2: Loading bulk data...
Adding 1â€¯000â€¯000 records...
Inserting 1â€¯000â€¯000 records in 100 batches of 10â€¯000...
  Completed 100â€¯000 / 1â€¯000â€¯000 records
  Completed 200â€¯000 / 1â€¯000â€¯000 records
  Completed 300â€¯000 / 1â€¯000â€¯000 records
  Completed 100â€¯000 / 1â€¯000â€¯000 records
  Completed 200â€¯000 / 1â€¯000â€¯000 records
  Completed 300â€¯000 / 1â€¯000â€¯000 records
  Completed 400â€¯000 / 1â€¯000â€¯000 records
  Completed 500â€¯000 / 1â€¯000â€¯000 records
  Completed 600â€¯000 / 1â€¯000â€¯000 records
  Completed 700â€¯000 / 1â€¯000â€¯000 records
  Completed 800â€¯000 / 1â€¯000â€¯000 records
  Completed 400â€¯000 / 1â€¯000â€¯000 records
  Completed 500â€¯000 / 1â€¯000â€¯000 records
  Completed 600â€¯000 / 1â€¯000â€¯000 records
  Completed 700â€¯000 / 1â€¯000â€¯000 records
  Completed 800â€¯000 / 1â€¯000â€¯000 records
  Completed 900â€¯000 / 1â€¯000â€¯000 records
  Completed 1â€¯000â€¯000 / 1â€¯000â€¯000 records
  Completed 900â€¯000 / 1â€¯000â€¯000 records
  Completed 1â€¯000â€¯000 / 1â€¯000â€¯000 records
âœ… Bulk insert completed successfully
âœ… Bulk insert completed successfully
âœ… Bulk insert completed successfully
âœ… Bulk insert completed successfully
[30.44s] Bulk data insert
Database now contains 0 total records
Memory after bulk insert: {
  rss: 476,
  heapUsed: 66,
  heapTotal: 80,
  external: 21,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[80.12ms] Insert 2048 authors
[201.61ms] Pick authors
âœ… Bulk insert completed successfully
[30.44s] Bulk data insert
Database now contains 0 total records
Memory after bulk insert: {
  rss: 476,
  heapUsed: 66,
  heapTotal: 80,
  external: 21,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[80.12ms] Insert 2048 authors
[201.61ms] Pick authors



âœ… Bulk insert completed successfully
[30.44s] Bulk data insert
Database now contains 0 total records
Memory after bulk insert: {
  rss: 476,
  heapUsed: 66,
  heapTotal: 80,
  external: 21,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[80.12ms] Insert 2048 authors
[201.61ms] Pick authors

âœ… Bulk insert completed successfully
[30.44s] Bulk data insert
Database now contains 0 total records
Memory after bulk insert: {
  rss: 476,
  heapUsed: 66,
  heapTotal: 80,
  external: 21,
}

ğŸ“Š PHASE 3: Benchmark with populated database
âœ… Bulk insert completed successfully
[30.44s] Bulk data insert
Database now contains 0 total records
Memory after bulk insert: {
  rss: 476,
  heapUsed: 66,
  heapTotal: 80,
  external: 21,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
âœ… Bulk insert completed successfully
[30.44s] Bulk data insert
Database now contains 0 total records
Memory after bulk insert: {
  rss: 476,
  heapUsed: 66,
âœ… Bulk insert completed successfully
[30.44s] Bulk data insert
Database now contains 0 total records
Memory after bulk insert: {
  rss: 476,
  heapUsed: 66,
  heapTotal: 80,
  external: 21,
}
âœ… Bulk insert completed successfully
[30.44s] Bulk data insert
Database now contains 0 total records
Memory after bulk insert: {
  rss: 476,
  rss: 476,
  heapUsed: 66,
  heapTotal: 80,
  external: 21,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[80.12ms] Insert 2048 authors
[201.61ms] Pick authors
[173.03s] Select benchmark authors
[50.95ms] Complex analytical query
[5.21s] Aggregation query
Memory usage - Before: 476MB, After: 505MB, Diff: 29MB

ğŸ Benchmark complete!


# SQLite

bun run .\tests\sqlite-bun.ts
============================================================
ğŸ§ª SQLite (Bun) Performance Benchmark
============================================================

ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: {
  rss: 315,
  heapUsed: 0,
  heapTotal: 17,
  external: 0,
}

--- EMPTY DB BENCHMARK ---
[17.48ms] Insert 2048 authors
[7.51ms] Pick authors
[3.72ms] Select benchmark authors
[1.36ms] Complex analytical query
[1.05ms] Aggregation query
Memory usage - Before: 315MB, After: 325MB, Diff: 10MB

ğŸ“¦ PHASE 2: Loading bulk data...
Adding 1â€¯000â€¯000 records...
Inserting 1â€¯000â€¯000 records in 100 batches of 10â€¯000...
  Completed 100â€¯000 / 1â€¯000â€¯000 records
  Completed 200â€¯000 / 1â€¯000â€¯000 records
  Completed 300â€¯000 / 1â€¯000â€¯000 records
  Completed 400â€¯000 / 1â€¯000â€¯000 records
  Completed 500â€¯000 / 1â€¯000â€¯000 records
  Completed 600â€¯000 / 1â€¯000â€¯000 records
  Completed 700â€¯000 / 1â€¯000â€¯000 records
  Completed 800â€¯000 / 1â€¯000â€¯000 records
  Completed 900â€¯000 / 1â€¯000â€¯000 records
  Completed 1â€¯000â€¯000 / 1â€¯000â€¯000 records
âœ… Bulk insert completed successfully
[10.32s] Bulk data insert
Database now contains 1â€¯002â€¯048 total records
Memory after bulk insert: {
  rss: 366,
  heapUsed: 15,
  heapTotal: 50,
  external: 5,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[187.52ms] Insert 2048 authors
[11.19ms] Pick authors
[4.81ms] Select benchmark authors
[548.97ms] Complex analytical query
[255.91ms] Aggregation query
Memory usage - Before: 366MB, After: 363MB, Diff: -3MB

ğŸ Benchmark complete!


# LevelDB

bun run .\tests\levelup.ts
============================================================
ğŸ§ª LevelDB Performance Benchmark
============================================================

ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: {
  rss: 147,
  heapUsed: 0,
  heapTotal: 2,
  external: 0,
}

--- EMPTY DB BENCHMARK ---
[48.38ms] Insert 2048 key-value pairs
[16.43ms] Pick key-value pairs
PS C:\Users\Mad Mat\code\benchmark-postgres-surrealdb-myrocks-cratedb> bun run .\tests\levelup.ts
============================================================
ğŸ§ª LevelDB Performance Benchmark
============================================================

ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: {
  rss: 147,
  heapUsed: 0,
  heapTotal: 2,
  external: 0,
}

--- EMPTY DB BENCHMARK ---
[48.38ms] Insert 2048 key-value pairs
[16.43ms] Pick key-value pairs
  heapUsed: 0,
  heapTotal: 2,
  external: 0,
}

--- EMPTY DB BENCHMARK ---
[48.38ms] Insert 2048 key-value pairs
[16.43ms] Pick key-value pairs
[48.38ms] Insert 2048 key-value pairs
[16.43ms] Pick key-value pairs
[16.43ms] Pick key-value pairs
[9.19ms] Batch get operation
[13.30ms] Range scan (first 1000)
[0.98ms] Key existence check
[0.98ms] Key existence check
Memory usage - Before: 147MB, After: 243MB, Diff: 96MB
Memory usage - Before: 147MB, After: 243MB, Diff: 96MB

ğŸ“¦ PHASE 2: Loading bulk data...
Adding 1â€¯000â€¯000 records...
Inserting 1â€¯000â€¯000 records in 100 batches of 10â€¯000...
  Completed 100â€¯000 / 1â€¯000â€¯000 records
  Completed 200â€¯000 / 1â€¯000â€¯000 records
  Completed 300â€¯000 / 1â€¯000â€¯000 records
  Completed 400â€¯000 / 1â€¯000â€¯000 records
  Completed 500â€¯000 / 1â€¯000â€¯000 records
  Completed 600â€¯000 / 1â€¯000â€¯000 records
  Completed 700â€¯000 / 1â€¯000â€¯000 records
  Completed 800â€¯000 / 1â€¯000â€¯000 records
  Completed 900â€¯000 / 1â€¯000â€¯000 records
  Completed 1â€¯000â€¯000 / 1â€¯000â€¯000 records
âœ… Bulk insert completed successfully
[29.30s] Bulk data insert
Database now contains ~1â€¯000â€¯000 + 2048 total records
Memory after bulk insert: {
  rss: 357,
  heapUsed: 22,
  heapTotal: 50,
  external: 2,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[20.07ms] Insert 2048 key-value pairs
[12.31ms] Pick key-value pairs
[9.87ms] Batch get operation
[5.80ms] Range scan (first 1000)
[0.65ms] Key existence check
Memory usage - Before: 357MB, After: 376MB, Diff: 19MB

ğŸ Benchmark complete!


# LMDB

bun tsx .\tests\lmdb.ts
============================================================
ğŸ§ª LMDB Performance Benchmark
============================================================

ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: { rss: 52, heapUsed: 9, heapTotal: 18, external: 1 }

--- EMPTY DB BENCHMARK ---
Insert 2048 key-value pairs: 226.169ms
Pick key-value pairs: 9.984ms
Batch get operation: 4.144ms
Range scan (first 1000): 8.118ms
Key existence check: 0.634ms
Memory usage - Before: 52MB, After: 78MB, Diff: 26MB

ğŸ“¦ PHASE 2: Loading bulk data...
Adding 1â€¯000â€¯000 records...
Inserting 1â€¯000â€¯000 records in 100 batches of 10â€¯000...
  Completed 100â€¯000 / 1â€¯000â€¯000 records
  Completed 200â€¯000 / 1â€¯000â€¯000 records
  Completed 300â€¯000 / 1â€¯000â€¯000 records
  Completed 400â€¯000 / 1â€¯000â€¯000 records
  Completed 500â€¯000 / 1â€¯000â€¯000 records
  Completed 600â€¯000 / 1â€¯000â€¯000 records
  Completed 700â€¯000 / 1â€¯000â€¯000 records
  Completed 800â€¯000 / 1â€¯000â€¯000 records
  Completed 900â€¯000 / 1â€¯000â€¯000 records
  Completed 1â€¯000â€¯000 / 1â€¯000â€¯000 records
âœ… Bulk insert completed successfully
Bulk data insert: 48.658s
Database now contains ~1â€¯000â€¯000 + 2048 total records
Memory after bulk insert: { rss: 1986, heapUsed: 10, heapTotal: 51, external: 1 }

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
Insert 2048 key-value pairs: 42.136ms
Pick key-value pairs: 6.014ms
Batch get operation: 4.594ms
Range scan (first 1000): 2.69ms
Key existence check: 0.198ms
Memory usage - Before: 1986MB, After: 1992MB, Diff: 6MB

ğŸ Benchmark complete!


# DuckDB

bun run .\tests\duckdb.ts
============================================================
ğŸ§ª DuckDB Performance Benchmark
============================================================

ğŸ“Š PHASE 1: Benchmark with empty database
Memory before: {
  rss: 309,
  heapUsed: 15,
  heapTotal: 18,
  external: 5,
}

--- EMPTY DB BENCHMARK ---
[5.24s] Insert 2048 authors
[495.69ms] Pick authors
[41.99ms] Select benchmark authors
[3.09ms] Complex analytical query
[1.13ms] Aggregation query
Memory usage - Before: 309MB, After: 420MB, Diff: 111MB

ğŸ“¦ PHASE 2: Loading bulk data...
Adding 1â€¯000â€¯000 records...
Inserting 1â€¯000â€¯000 records in 100 batches of 10â€¯000...
  Completed 100â€¯000 / 1â€¯000â€¯000 records
  Completed 200â€¯000 / 1â€¯000â€¯000 records
  Completed 300â€¯000 / 1â€¯000â€¯000 records
  Completed 400â€¯000 / 1â€¯000â€¯000 records
  Completed 500â€¯000 / 1â€¯000â€¯000 records
  Completed 600â€¯000 / 1â€¯000â€¯000 records
  Completed 700â€¯000 / 1â€¯000â€¯000 records
  Completed 800â€¯000 / 1â€¯000â€¯000 records
  Completed 900â€¯000 / 1â€¯000â€¯000 records
  Completed 1â€¯000â€¯000 / 1â€¯000â€¯000 records
âœ… Bulk insert completed successfully
[348.42s] Bulk data insert
Database now contains 1â€¯002â€¯048 total records
Memory after bulk insert: {
  rss: 392,
  heapUsed: 15,
  heapTotal: 23,
  external: 4,
}

ğŸ“Š PHASE 3: Benchmark with populated database

--- POPULATED DB BENCHMARK ---
[5.47s] Insert 2048 authors
[589.57ms] Pick authors
[48.45ms] Select benchmark authors
[28.79ms] Complex analytical query
[11.92ms] Aggregation query
Memory usage - Before: 392MB, After: 565MB, Diff: 173MB

ğŸ Benchmark complete!
